# Incidente Microsoftâ€¯Azure â€” 29 de octubre de 2025

## 1) LÃ­nea de tiempo  

### ðŸ•’ ~15:45â€¯UTC (â‰ˆâ€¯11:45â€¯a.m.â€¯ET)  
- Las primeras alertas visibles: monitorizaciÃ³n de terceros (por ejemplo Cisco ThousandEyes) detecta anomalÃ­as en Azure Front Door (AFD)â€‘red global/ingreso de trÃ¡fico.  
- Usuarios comienzan a reportar fallos de acceso a servicios de Microsoft (por ejemplo Microsoft 365, Xbox Live) y otros sitios web dependientes.  

### ~16:00â€¯UTC (â‰ˆâ€¯12:00â€¯p.m.â€¯ET)  
- Microsoft confirma que â€œstarting at approximately 16:00â€¯UTC â€¦ customers and Microsoft services leveraging Azure Front Door (AFD) may have experienced latencies, timeouts, and errors.â€  
- En su portal de estado, Microsoft publica que la causa es una â€œconfiguration changeâ€ involuntaria que impactÃ³ AFD.  

### ~17:26â€¯UTC  
- Microsoft registra que el portal de Azure â€œfell away from Azure Front Doorâ€ (es decir, el portal interno se desligÃ³ de AFD como medida de contenciÃ³n).  

### ~17:30â€¯UTC  
- Microsoft bloquea **todos los nuevos cambios de configuraciÃ³n** en AFD para evitar propagaciÃ³n del estado errÃ³neo.  

### ~18:30â€‘18:45â€¯UTC  
- Comienza el despliegue de la â€œlast known good configurationâ€ (Ãºltima configuraciÃ³n conocida buena) a nivel global en AFD.  
- Se inicia recuperaciÃ³n manual de nodos de borde (edge nodes) y reâ€‘equilibrio del trÃ¡fico hacia nodos sanos.  

### ~00:05â€¯UTC (30â€¯oct)  
- Microsoft confirma que el impacto de AFD estÃ¡ mitigado (â€œAFD impact confirmed mitigated for customersâ€).  

### Periodo de impacto total  
- El evento durÃ³ **mÃ¡s de 8â€¯horas**, desde aproximadamente 12â€¯p.m.â€¯ET (16:00â€¯UTC) hasta ~00:05â€¯UTC del dÃ­a siguiente para mitigaciÃ³n completa.  

---

## 2) VersiÃ³n oficial de Microsoft  
- Microsoft indica que el problema fue causado por un cambio de configuraciÃ³n inadvertido en AFD y que la infraestructura de AFD (nodos globales) perdiÃ³ salud y no pudo enrutar correctamente el trÃ¡fico.  
- â€œWhile error rates and latency are back to preâ€‘incident levels, a small number of customers may still be seeing issuesâ€¦â€ â€” Microsoft declara que estÃ¡ en proceso de mitigaciÃ³n de â€œcola largaâ€.  
- Microsoft recomienda que los clientes implementen estrategias de failâ€‘over, por ejemplo usar Azure Traffic Manager para redirigir trÃ¡fico mientras AFD se estabiliza.  

---

## 3) VersiÃ³n no oficial / prensa / analistas  
- Varios medios indican que la caÃ­da afectÃ³ no solo los servicios de Microsoft, sino tambiÃ©n organizaciones que dependen de Azure (por ejemplo Alaska Airlines, Starbucks Corporation, Costco Wholesale Corporation) que vieron caÃ­das en sus webs/apps.  
- Analistas seÃ±alan que otro factor crÃ­tico fue la dependencia de un solo tejido global de borde (AFD) para distribuciÃ³n de contenido y routing de apps globales; cuando falla ese tejido, el â€œblast radiusâ€ es amplio.  
- En foros tÃ©cnicos usuarios comentan que el estallido fue visible incluso para recursos que no estaban directamente en Azureâ€¯Frontâ€‘Door pero dependÃ­an de Ã©l para servicios frontend, DNS, autenticaciÃ³n.  

---

## 4) Impacto en el ecosistema  
- Servicios afectados: Microsoftâ€¯365 (incluyendo Outlook, Teams), Xbox, Minecraft, Azure Portal, otros servicios de Azure (App Service, SQLâ€¯DB, Virtualâ€¯Desktop, etc.).  
- Empresas externas afectadas: Alaskaâ€¯Airlines, Starbucks, Costco.  
- La caÃ­da refuerza la llamada atenciÃ³n sobre riesgos de centralizaciÃ³n de infraestructura cloud y la importancia de resiliencia en la capa de distribuciÃ³n global.  

---

## 5) Lecciones tÃ©cnicas para arquitecturas cloud  
1. Un cambio de configuraciÃ³n **global** en un servicio de borde/routing (como AFD) puede provocar mÃ¡s impacto que fallas en instancias individuales.  
2. La capa de â€œingreso global / distribuciÃ³n de contenidos / roteoâ€ es crÃ­tica.  
3. Implementar rollback automÃ¡tico y validaciÃ³n canary para cambios globales.  
4. DiseÃ±ar fallback activo para servicios de distribuciÃ³n global.  
5. Considerar escenarios de fallo global del proveedor.  

---

## 6) Checklist de resiliencia para cargas en Azure  
- Verificar **dependencias de Azureâ€¯Frontâ€¯Door (AFD)**.  
- Tener **failover de trÃ¡fico** con Azureâ€¯Trafficâ€¯Manager o CDN alterna.  
- Bloqueo de cambios globales sin validaciÃ³n previa.  
- TTL de DNS razonables y fallback.  
- Pruebas de degradaciÃ³n simulando pÃ©rdida del borde.  
- Monitorear la capa de borde y trÃ¡fico HTTP 502/504.  
- Acceso alternativo vÃ­a CLI/PowerShell si el portal cae.  

---

## 7) Preguntas para discusiÃ³n en clase  
1. Â¿QuÃ© diferencias hay entre un fallo regional y uno global de borde?  
2. Â¿CÃ³mo diseÃ±arÃ­as un fallback para Azureâ€¯Frontâ€¯Door?  
3. Â¿QuÃ© impacto tiene esto en los SLAs internos de negocio?  
4. Â¿QuÃ© seÃ±ales de monitoreo detectarÃ­an fallas en la capa de borde?  
5. Â¿Multiâ€‘nube es suficiente o hace falta algo mÃ¡s?  

---

> **Fuentes clave:**  
> - Reuters: Microsoft Azureâ€™s services restored after global outage.  
> - Tomâ€™s Guide: Microsoft was down â€” live updates on outage.  
> - Data Center Knowledge: Microsoft Azure Outage: Web Services Down.  
> - Microsoft Azure Status History: Azure Front Door incident details.  
